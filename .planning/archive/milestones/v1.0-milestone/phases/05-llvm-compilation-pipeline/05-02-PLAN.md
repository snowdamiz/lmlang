---
phase: 05-llvm-compilation-pipeline
plan: 02
type: execute
wave: 2
depends_on: [05-01]
files_modified:
  - crates/lmlang-codegen/src/codegen.rs
autonomous: true
requirements: [EXEC-02]

must_haves:
  truths:
    - "Every Tier 1 op node (arithmetic, comparison, logic, shifts, control flow, memory, functions, I/O, closures) emits correct LLVM IR"
    - "Every Tier 2 op node (struct/array/enum operations, casts) emits correct LLVM IR"
    - "Control flow ops (IfElse, Loop, Match, Branch, Jump, Phi) produce correct basic block structure"
    - "Runtime guards are emitted before division, checked arithmetic uses overflow intrinsics"
    - "Function calls resolve to LLVM call instructions targeting compiled functions"
  artifacts:
    - path: "crates/lmlang-codegen/src/codegen.rs"
      provides: "Per-function code generation with compile_function and per-op emit functions"
      min_lines: 400
  key_links:
    - from: "crates/lmlang-codegen/src/codegen.rs"
      to: "lmlang-core ComputeNodeOp"
      via: "exhaustive match on ComputeOp and StructuredOp variants"
      pattern: "ComputeOp::|StructuredOp::"
    - from: "crates/lmlang-codegen/src/codegen.rs"
      to: "crates/lmlang-codegen/src/types.rs"
      via: "lm_type_to_llvm for typed operations"
      pattern: "lm_type_to_llvm"
    - from: "crates/lmlang-codegen/src/codegen.rs"
      to: "crates/lmlang-codegen/src/runtime.rs"
      via: "emit_div_guard, emit_overflow_guard, emit_bounds_guard for runtime checks"
      pattern: "emit_div_guard|emit_overflow_guard|emit_bounds_guard"
---

<objective>
Implement per-function code generation that lowers every op node in the computational graph to LLVM IR instructions, handling SSA form, basic block structure for control flow, and runtime safety checks.

Purpose: This is the core of the LLVM compilation pipeline -- translating the graph IR into LLVM IR. Without this, graphs cannot become executables.
Output: codegen.rs with compile_function and all per-op emit functions covering all ~34 operations.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-llvm-compilation-pipeline/05-RESEARCH.md
@.planning/phases/05-llvm-compilation-pipeline/05-CONTEXT.md
@.planning/phases/05-llvm-compilation-pipeline/05-01-SUMMARY.md
@crates/lmlang-core/src/ops.rs
@crates/lmlang-core/src/node.rs
@crates/lmlang-core/src/edge.rs
@crates/lmlang-core/src/graph.rs
@crates/lmlang-core/src/function.rs
@crates/lmlang-core/src/types.rs
@crates/lmlang-codegen/src/types.rs
@crates/lmlang-codegen/src/runtime.rs
@crates/lmlang-codegen/src/error.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Function compilation framework and arithmetic/logic/comparison ops</name>
  <files>
    crates/lmlang-codegen/src/codegen.rs
  </files>
  <action>
Create `codegen.rs` with the per-function compilation framework and implement all arithmetic, logic, comparison, shift, and simple ops.

**Core framework:**

```rust
pub fn compile_function<'ctx>(
    context: &'ctx Context,
    module: &Module<'ctx>,
    builder: &Builder<'ctx>,
    graph: &ProgramGraph,
    func_id: FunctionId,
    func_def: &FunctionDef,
) -> Result<FunctionValue<'ctx>, CodegenError>
```

Steps within compile_function:
1. Create LLVM function with correct signature -- map each param type via `lm_type_to_llvm`, map return type, create fn_type and add_function
2. Create entry basic block, position builder at end
3. Collect function nodes via `graph.function_nodes(func_id)`
4. Topological sort by data edges (implement `topological_sort` using Kahn's algorithm on data edges within the function)
5. Create `values: HashMap<NodeId, BasicValueEnum<'ctx>>` for SSA value tracking
6. Create `basic_blocks: HashMap<NodeId, BasicBlock<'ctx>>` for control flow node block tracking
7. Iterate sorted nodes, dispatch to per-op emit functions via exhaustive match on `ComputeNodeOp`
8. Return the FunctionValue

**Topological sort** (`topological_sort`):
- Input: list of NodeIds belonging to function, reference to ProgramGraph
- Build in-degree map from data edges (only edges where both source and target are in the function node set)
- Kahn's algorithm: start with zero in-degree nodes, process queue, add newly zero-degree nodes
- Return ordered Vec<NodeId>
- Nodes with no data dependencies (Const, Parameter, Alloc, CaptureAccess, ReadLine) naturally sort first

**Per-op emit function:**
```rust
fn emit_node<'ctx>(
    context: &'ctx Context,
    module: &Module<'ctx>,
    builder: &Builder<'ctx>,
    graph: &ProgramGraph,
    function: FunctionValue<'ctx>,
    node_id: NodeId,
    op: &ComputeNodeOp,
    values: &mut HashMap<NodeId, BasicValueEnum<'ctx>>,
    basic_blocks: &mut HashMap<NodeId, BasicBlock<'ctx>>,
) -> Result<(), CodegenError>
```

**Helper to get input values:**
```rust
fn get_input<'ctx>(
    graph: &ProgramGraph,
    node_id: NodeId,
    port: u16,
    values: &HashMap<NodeId, BasicValueEnum<'ctx>>,
) -> Result<BasicValueEnum<'ctx>, CodegenError>
```
Looks up incoming data edges to `node_id` at `target_port == port`, finds the source node, looks up its value in the `values` map.

**Implement these ops in the emit_node match:**

**Constants (ComputeOp::Const):**
- Bool: `context.bool_type().const_int(v as u64, false)`
- I8/I16/I32/I64: `context.iN_type().const_int(v as u64, true)` (signed)
- F32: `context.f32_type().const_float(v)` (narrow from f64 storage)
- F64: `context.f64_type().const_float(v)`
- Unit: `context.struct_type(&[], false).get_undef()` or const_zero

**Parameter (ComputeOp::Parameter { index }):**
- `function.get_nth_param(index as u32)` -- lookup LLVM function param directly

**BinaryArith (ComputeOp::BinaryArith { op }):**
- Get lhs (port 0) and rhs (port 1) from values map
- Determine if integer or float from the value types
- For integer ops:
  - Add/Sub/Mul: use overflow intrinsics (`llvm.sadd.with.overflow.iN` etc.) -- declare intrinsic via `module.add_function`, call it, extract result and overflow flag, branch to error on overflow via `emit_overflow_guard`
  - Div/Rem: call `emit_div_guard` first, then `builder.build_int_signed_div` / `build_int_signed_rem`
- For float ops: `build_float_add/sub/mul/div/rem` (no guards needed for float)

**UnaryArith (ComputeOp::UnaryArith { op }):**
- Neg: int `builder.build_int_neg`, float `builder.build_float_neg`
- Abs: int -- use select on comparison with zero; float -- declare `llvm.fabs.fN` intrinsic and call

**Compare (ComputeOp::Compare { op }):**
- Int: `builder.build_int_compare(predicate, lhs, rhs, "cmp")` with predicate from CmpOp
  - Eq->EQ, Ne->NE, Lt->SLT, Le->SLE, Gt->SGT, Ge->SGE
- Float: `builder.build_float_compare(predicate, lhs, rhs, "cmp")`
  - Eq->OEQ, Ne->UNE, Lt->OLT, Le->OLE, Gt->OGT, Ge->OGE

**BinaryLogic (ComputeOp::BinaryLogic { op }):**
- And: `builder.build_and(lhs, rhs, "and")`
- Or: `builder.build_or(lhs, rhs, "or")`
- Xor: `builder.build_xor(lhs, rhs, "xor")`

**Not (ComputeOp::Not):**
- `builder.build_not(val, "not")`

**Shift (ComputeOp::Shift { op }):**
- Shl: `builder.build_left_shift(val, amt, "shl")`
- ShrLogical: `builder.build_right_shift(val, amt, false, "lshr")`
- ShrArith: `builder.build_right_shift(val, amt, true, "ashr")`

**Print (ComputeOp::Print):**
- Call `emit_print_value` from runtime.rs

**Return (ComputeOp::Return):**
- Get return value from port 0 (if not void)
- `builder.build_return(Some(&val))` or `builder.build_return(None)` for unit

Register the module in lib.rs with `pub mod codegen;`

This task covers: Const, Parameter, BinaryArith (5 ops), UnaryArith (2 ops), Compare (6 ops), BinaryLogic (3 ops), Not, Shift (3 ops), Print, Return = ~22 op variants. The remaining ops (control flow, memory, functions, closures, structured) are in Task 2.
  </action>
  <verify>
`cargo check -p lmlang-codegen` compiles. The codegen module is registered. The compile_function, topological_sort, emit_node, and get_input functions exist and handle all arithmetic/logic/comparison/shift/print/return ops.
  </verify>
  <done>
Per-function compilation framework works. All arithmetic ops use overflow intrinsics with error guards. All comparison, logic, shift, print, return ops emit correct LLVM IR. Topological sort orders nodes correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Control flow, memory, function calls, closures, and structured ops</name>
  <files>
    crates/lmlang-codegen/src/codegen.rs
  </files>
  <action>
Add the remaining op implementations to the emit_node match in codegen.rs. These are the more complex ops requiring basic block management.

**Control Flow ops:**

**IfElse (ComputeOp::IfElse):**
- Get condition from port 0
- Create three basic blocks: then_bb, else_bb, merge_bb
- `builder.build_conditional_branch(cond, then_bb, else_bb)`
- Store then_bb and else_bb in basic_blocks map keyed by node_id (convention: use separate map or tuple)
- The IfElse node's control successors (branch_index 0 = then, 1 = else) will be emitted into appropriate blocks
- After both branches complete, position at merge_bb
- NOTE: The actual branch body nodes are emitted by topological order and use the basic_blocks map to know which block they belong to. Alternatively, handle IfElse as a control flow region: identify then-body and else-body nodes via control edges, emit them in their respective blocks, add unconditional branches to merge_bb.

Implementation approach: Two-pass within compile_function:
1. First pass: identify control flow regions (IfElse/Loop/Match nodes and their controlled node sets via control edges)
2. Second pass: emit nodes, positioning builder at correct basic block based on control region membership

Actually, simpler approach: handle control flow nodes inline during emission. When encountering IfElse:
- Create then_bb, else_bb, merge_bb
- Emit conditional branch
- Record in a `control_regions: HashMap<NodeId, ControlRegion>` that maps the IfElse node to its blocks
- When emitting subsequent nodes, check if they have an incoming control edge from a control flow node, and position builder at the appropriate basic block before emitting

**Loop (ComputeOp::Loop):**
- Create header_bb, body_bb, exit_bb
- In header: get condition from port 0, branch on condition to body_bb or exit_bb
- Body nodes are those controlled by branch_index 0
- At end of body, unconditional branch back to header_bb
- After loop, position at exit_bb

**Match (ComputeOp::Match):**
- Get discriminant from port 0 (must be integer)
- Create one basic block per arm + default_bb + merge_bb
- `builder.build_switch(discriminant, default_bb, &[(const_0, arm0_bb), ...])`
- Each arm branches to merge_bb when done

**Branch (ComputeOp::Branch):**
- Get condition from port 0
- Find true_bb and false_bb from control successors (branch_index 0 and 1)
- `builder.build_conditional_branch(cond, true_bb, false_bb)`

**Jump (ComputeOp::Jump):**
- Find target block from control successor
- `builder.build_unconditional_branch(target_bb)`

**Phi (ComputeOp::Phi):**
- Create phi node with `builder.build_phi(ty, "phi")`
- Add incoming values from predecessor basic blocks
- The predecessor values come from data edges at ports matching the branch indices

**Memory ops:**

**Alloc (ComputeOp::Alloc):**
- Determine type from outgoing data edge's value_type (the edge going out of this alloc tells us the pointer-to type; look at the edge's value_type which should be Pointer, and dereference to get the pointee type; OR infer from Load/Store successors)
- Actually: the Alloc node produces a pointer. The type to allocate is determined by looking at what Store/Load ops use this pointer with. For simplicity, look at the outgoing edge value_type which is a Pointer type, extract the pointee from TypeRegistry.
- `builder.build_alloca(pointee_llvm_type, "alloc")`

**Load (ComputeOp::Load):**
- Get pointer from port 0
- Determine loaded type from outgoing data edge value_type
- `builder.build_load(loaded_llvm_type, ptr, "load")`

**Store (ComputeOp::Store):**
- Get pointer from port 0, value from port 1
- `builder.build_store(ptr, val)`
- Store produces no SSA value (do not insert into values map)

**GetElementPtr (ComputeOp::GetElementPtr):**
- Get base pointer from port 0, index from port 1
- Determine element type from the pointer's pointee type
- `builder.build_in_bounds_gep(elem_type, base, &[index], "gep")` (or build_struct_gep for struct field access)

**Function call ops:**

**Call (ComputeOp::Call { target }):**
- Look up target function name from FunctionDef
- Get LLVM function via `module.get_function(&target_name)`
- Collect argument values from data input edges (ports 0, 1, 2, ...)
- `builder.build_call(target_fn, &args, "call")`
- Extract return value if non-void

**IndirectCall (ComputeOp::IndirectCall):**
- Get function pointer from port 0
- Collect remaining args from ports 1, 2, ...
- Determine function type from the pointer type
- `builder.build_indirect_call(fn_type, fn_ptr, &args, "icall")`

**Closure ops:**

**MakeClosure (ComputeOp::MakeClosure { function }):**
- Allocate environment struct on stack (alloca)
- Store each capture value (from data input edges) into the struct fields
- Produce a pair: `{ function_pointer, environment_pointer }` as an LLVM struct
- Per discretion: use stack allocation initially (closures don't escape scope in Phase 5)

**CaptureAccess (ComputeOp::CaptureAccess { index }):**
- The environment pointer is passed as the last parameter of the closure function
- GEP into the environment struct at the given index
- Load the value

**I/O ops (basic support):**

**ReadLine (ComputeOp::ReadLine):** Emit a call to a declared `lmlang_readline` stub or simple `fgets` wrapper. For Phase 5, can be a stub that returns empty or reads from stdin.

**FileOpen/FileRead/FileWrite/FileClose:** Emit calls to declared fopen/fread/fwrite/fclose wrappers. These can be minimal stubs for Phase 5 -- full file I/O testing is not a Phase 5 goal.

**Structured ops (Tier 2):**

**StructCreate (StructuredOp::StructCreate { type_id }):**
- Build an LLVM struct value by sequential `insertvalue` for each field from input ports
- Each input port corresponds to a struct field in declaration order

**StructGet (StructuredOp::StructGet { field_index }):**
- `builder.build_extract_value(struct_val, field_index, "sget")`

**StructSet (StructuredOp::StructSet { field_index }):**
- Get struct from port 0, new value from port 1
- `builder.build_insert_value(struct_val, new_val, field_index, "sset")`

**ArrayCreate (StructuredOp::ArrayCreate { length }):**
- Build array value via sequential `insertvalue` from input ports

**ArrayGet (StructuredOp::ArrayGet):**
- Get array from port 0, index from port 1
- If index is constant: `builder.build_extract_value(arr, const_idx, "aget")`
- If dynamic: alloca the array, GEP to element, load -- with bounds guard via `emit_bounds_guard`

**ArraySet (StructuredOp::ArraySet):**
- Get array from port 0, index from port 1, value from port 2
- If constant: `builder.build_insert_value(arr, val, const_idx, "aset")`
- If dynamic: alloca, GEP, store, reload full array -- with bounds guard

**Cast (StructuredOp::Cast { target_type }):**
- Determine source type from input edge, target from target_type
- Select LLVM cast operation: int->int (trunc/sext based on widths), float->float (fptrunc/fpext), int->float (sitofp), float->int (fptosi), bool->int (zext), int->bool (trunc to i1)

**EnumCreate (StructuredOp::EnumCreate { type_id, variant_index }):**
- Create the tagged union struct: `{ i32 discriminant, [payload_size x i8] }`
- insertvalue discriminant, bitcast payload to [N x i8], insertvalue payload

**EnumDiscriminant (StructuredOp::EnumDiscriminant):**
- `builder.build_extract_value(enum_val, 0, "disc")`

**EnumPayload (StructuredOp::EnumPayload { variant_index }):**
- `builder.build_extract_value(enum_val, 1, "payload_raw")` then bitcast to variant's payload type

Ensure the match on ComputeNodeOp is exhaustive -- every variant handled or returns CodegenError::UnsupportedOp.
  </action>
  <verify>
`cargo check -p lmlang-codegen` compiles. All ComputeNodeOp variants are handled in the match (no wildcards). Control flow ops create appropriate basic blocks with correct branch/phi structure.
  </verify>
  <done>
All ~34 op nodes have LLVM IR emission implementations. Control flow creates correct basic block structures. Memory ops map to alloca/load/store. Function calls resolve correctly. Structured ops handle struct/array/enum operations. The exhaustive match covers every ComputeNodeOp variant.
  </done>
</task>

</tasks>

<verification>
- `cargo check -p lmlang-codegen` compiles without errors
- Every ComputeOp and StructuredOp variant is handled in emit_node (exhaustive match, no wildcards)
- compile_function produces an LLVM FunctionValue with correct signature
- Topological sort handles both linear and branching graphs
- Runtime guards are emitted before dangerous operations (div, rem, array access)
- Checked arithmetic uses overflow intrinsics for integer add/sub/mul
</verification>

<success_criteria>
- All ~34 op node types have LLVM IR emission code
- Control flow ops (IfElse, Loop, Match, Branch, Jump, Phi) create correct multi-block structures
- Memory ops (Alloc, Load, Store, GEP) emit correct alloca/load/store/gep
- Function calls emit correct LLVM call instructions
- Struct/Array/Enum operations use insertvalue/extractvalue correctly
- Division is guarded, integer arithmetic uses overflow intrinsics
- `cargo check -p lmlang-codegen` passes
</success_criteria>

<output>
After completion, create `.planning/phases/05-llvm-compilation-pipeline/05-02-SUMMARY.md`
</output>

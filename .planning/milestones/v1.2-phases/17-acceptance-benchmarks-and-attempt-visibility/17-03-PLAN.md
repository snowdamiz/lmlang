---
phase: 17-acceptance-benchmarks-and-attempt-visibility
plan: 03
type: execute
wave: 3
depends_on:
  - "17-01"
  - "17-02"
files_modified:
  - crates/lmlang-server/static/dashboard/index.html
  - crates/lmlang-server/static/dashboard/app.js
  - crates/lmlang-server/static/dashboard/styles.css
  - crates/lmlang-server/src/handlers/dashboard.rs
  - crates/lmlang-server/tests/integration_test.rs
  - docs/api/operator-endpoints.md
autonomous: true
requirements:
  - AUT-09
  - AUT-10
  - AUT-11

must_haves:
  truths:
    - "Dashboard/visibility surfaces expose each autonomous attempt step, outputs, and final outcome in an operator-readable timeline view"
    - "Timeline UX consumes structured attempt-history fields instead of transcript heuristics"
    - "Operator docs explain how to interpret benchmark attempt records and final statuses"
    - "End-to-end tests validate timeline payload integrity for benchmark scenarios"
  artifacts:
    - path: "crates/lmlang-server/static/dashboard/app.js"
      provides: "Client-side rendering of autonomous attempt timeline rows, diagnostics summaries, and final outcome markers"
      contains: "execution"
    - path: "crates/lmlang-server/static/dashboard/index.html"
      provides: "Dashboard layout section for attempt-history/timeline visibility"
      contains: "timeline"
    - path: "crates/lmlang-server/src/handlers/dashboard.rs"
      provides: "Dashboard chat endpoint payload wiring for timeline fields consumed by UI"
      contains: "DashboardAiChatResponse"
    - path: "docs/api/operator-endpoints.md"
      provides: "Operator-facing reference for benchmark timeline fields and example payloads"
      contains: "AUT-09"
    - path: "crates/lmlang-server/tests/integration_test.rs"
      provides: "Integration assertions for timeline payload presence/shape in dashboard and agent flows"
      contains: "phase17"
  key_links:
    - from: "crates/lmlang-server/static/dashboard/app.js"
      to: "crates/lmlang-server/src/handlers/dashboard.rs"
      via: "UI timeline rendering consumes structured dashboard chat execution/timeline fields from handler responses"
      pattern: "/dashboard/ai/chat|execution|attempt"
    - from: "crates/lmlang-server/tests/integration_test.rs"
      to: "crates/lmlang-server/static/dashboard/app.js"
      via: "Tests confirm benchmark run payloads include timeline data required by dashboard rendering"
      pattern: "dashboard|execution|attempts"
    - from: "docs/api/operator-endpoints.md"
      to: "crates/lmlang-server/src/handlers/dashboard.rs"
      via: "Published timeline examples align with serialized dashboard response contract"
      pattern: "timeline|execution|diagnostics|stop_reason"
---

<objective>
Deliver operator-facing timeline/history visibility for benchmark autonomous attempts.

Purpose: Complete AUT-09 user-facing visibility and connect benchmark acceptance evidence to dashboard and documentation surfaces.
Output: Dashboard timeline UI, contract docs, and integration assertions for benchmark attempt visibility end-to-end.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/STATE.md
@.planning/phases/17-acceptance-benchmarks-and-attempt-visibility/17-RESEARCH.md
@.planning/phases/17-acceptance-benchmarks-and-attempt-visibility/17-01-PLAN.md
@.planning/phases/17-acceptance-benchmarks-and-attempt-visibility/17-02-PLAN.md
@crates/lmlang-server/static/dashboard/index.html
@crates/lmlang-server/static/dashboard/app.js
@crates/lmlang-server/static/dashboard/styles.css
@crates/lmlang-server/src/handlers/dashboard.rs
@crates/lmlang-server/tests/integration_test.rs
@docs/api/operator-endpoints.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement dashboard attempt timeline/history panels for autonomous runs</name>
  <files>
    crates/lmlang-server/static/dashboard/index.html
    crates/lmlang-server/static/dashboard/app.js
    crates/lmlang-server/static/dashboard/styles.css
    crates/lmlang-server/src/handlers/dashboard.rs
  </files>
  <action>
    Add a dedicated timeline/attempt visibility surface in dashboard UX that renders:
    - ordered attempts with attempt/max-attempts and planner status,
    - per-action step outputs and diagnostics summaries,
    - final stop reason/outcome markers.

    Keep chat orchestration intact while ensuring timeline refreshes with project-agent detail/dashboard chat updates.
  </action>
  <verify>
    Manual smoke plus automated checks confirm dashboard timeline displays structured attempt data for both success and failure benchmark runs.
  </verify>
  <done>
    Operators can review autonomous attempt progression and final outcomes directly in the dashboard.
  </done>
</task>

<task type="auto">
  <name>Task 2: Lock contract and docs for benchmark timeline visibility</name>
  <files>
    crates/lmlang-server/tests/integration_test.rs
    docs/api/operator-endpoints.md
  </files>
  <action>
    Extend integration coverage to assert timeline fields are present and consistent in benchmark-related responses.
    Update operator endpoint docs with:
    - timeline field reference,
    - benchmark response examples (calculator + additional prompts),
    - guidance for interpreting per-attempt outcomes and stop reasons.
  </action>
  <verify>
    Integration tests and docs examples agree on serialized field names and benchmark timeline semantics.
  </verify>
  <done>
    AUT-09 visibility behavior is test-backed and operator-documented for phase17 acceptance flows.
  </done>
</task>

</tasks>

<verification>
1. Dashboard includes a dedicated attempt timeline/history panel fed by structured execution data
2. Timeline renders attempt metadata, action outputs, diagnostics summaries, and terminal outcome
3. Integration tests validate timeline payload presence and shape for benchmark scenarios
4. Operator docs include accurate benchmark timeline examples and interpretation guidance
5. Existing chat-first orchestration behavior remains intact
</verification>

<success_criteria>
- AUT-09 satisfied end-to-end with operator-visible timeline/history views
- AUT-10 and AUT-11 benchmark outcomes are transparent and reviewable through dashboard/docs
- Phase 17 delivers both acceptance proof and attempt visibility for autonomy capability claims
</success_criteria>

<output>
After completion, create `.planning/phases/17-acceptance-benchmarks-and-attempt-visibility/17-03-SUMMARY.md`
</output>

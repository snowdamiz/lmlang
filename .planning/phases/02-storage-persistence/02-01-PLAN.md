---
phase: 02-storage-persistence
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/lmlang-storage/Cargo.toml
  - crates/lmlang-storage/src/lib.rs
  - crates/lmlang-storage/src/error.rs
  - crates/lmlang-storage/src/types.rs
  - crates/lmlang-storage/src/traits.rs
  - crates/lmlang-storage/src/convert.rs
  - crates/lmlang-storage/src/memory.rs
  - crates/lmlang-core/src/graph.rs
autonomous: true
requirements:
  - STORE-02

must_haves:
  truths:
    - "GraphStore trait defines low-level CRUD for nodes, edges, types, functions, modules plus query methods"
    - "InMemoryStore implements GraphStore as a first-class backend for tests and ephemeral sessions"
    - "ProgramGraph can be decomposed to flat rows and recomposed back with all nodes, edges, types, functions, modules, and semantic data intact"
    - "ProgramId is defined in lmlang-storage as a storage-layer concern"
  artifacts:
    - path: "crates/lmlang-storage/src/traits.rs"
      provides: "GraphStore trait definition"
      min_lines: 60
    - path: "crates/lmlang-storage/src/memory.rs"
      provides: "InMemoryStore implementation of GraphStore"
      min_lines: 80
    - path: "crates/lmlang-storage/src/convert.rs"
      provides: "ProgramGraph decompose/recompose functions"
      min_lines: 60
    - path: "crates/lmlang-storage/src/error.rs"
      provides: "StorageError enum with all failure modes"
      min_lines: 20
  key_links:
    - from: "crates/lmlang-storage/src/memory.rs"
      to: "crates/lmlang-storage/src/traits.rs"
      via: "impl GraphStore for InMemoryStore"
      pattern: "impl GraphStore for InMemoryStore"
    - from: "crates/lmlang-storage/src/convert.rs"
      to: "crates/lmlang-core/src/graph.rs"
      via: "decompose/recompose uses ProgramGraph accessors"
      pattern: "ProgramGraph"
    - from: "crates/lmlang-storage/src/traits.rs"
      to: "crates/lmlang-core"
      via: "trait methods use lmlang-core types (ComputeNode, FlowEdge, etc.)"
      pattern: "ComputeNode|FlowEdge|FunctionDef|ModuleDef"
---

<objective>
Create the lmlang-storage crate with the GraphStore trait abstraction, StorageError types, ProgramId, ProgramGraph decompose/recompose conversion, and a production-quality InMemoryStore implementation.

Purpose: Establishes the storage contract (STORE-02) that all backends implement, plus the first-class in-memory backend used for tests, ephemeral agent sessions, and anywhere persistence isn't needed. The trait's two-layer API (low-level CRUD + high-level convenience) ensures backends stay swappable without changing core logic.

Output: Working lmlang-storage crate with InMemoryStore that passes save/load roundtrip tests.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-storage-persistence/02-RESEARCH.md
@.planning/phases/02-storage-persistence/02-CONTEXT.md
@crates/lmlang-core/src/lib.rs
@crates/lmlang-core/src/graph.rs
@crates/lmlang-core/src/id.rs
@crates/lmlang-core/src/node.rs
@crates/lmlang-core/src/edge.rs
@crates/lmlang-core/src/function.rs
@crates/lmlang-core/src/module.rs
@crates/lmlang-core/src/type_id.rs
@crates/lmlang-core/src/types.rs
@crates/lmlang-core/src/error.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create lmlang-storage crate with trait, error types, ProgramId, and ProgramGraph accessors</name>
  <files>
    crates/lmlang-storage/Cargo.toml
    crates/lmlang-storage/src/lib.rs
    crates/lmlang-storage/src/error.rs
    crates/lmlang-storage/src/types.rs
    crates/lmlang-storage/src/traits.rs
    crates/lmlang-core/src/graph.rs
  </files>
  <action>
1. Create `crates/lmlang-storage/Cargo.toml`:
   - Package name `lmlang-storage`, edition 2021
   - Dependencies: `lmlang-core = { path = "../lmlang-core" }`, `serde = { version = "1", features = ["derive"] }`, `serde_json = "1"`, `thiserror = "2"`
   - Dev-dependencies: (none yet, tests use the crate itself)

2. Create `crates/lmlang-storage/src/error.rs`:
   - `StorageError` enum with `#[derive(Debug, Error)]` using thiserror
   - Variants: `Serialization(#[from] serde_json::Error)`, `ProgramNotFound(i64)`, `NodeNotFound { program: i64, node: u32 }`, `EdgeNotFound { program: i64, edge: u32 }`, `FunctionNotFound { program: i64, function: u32 }`, `ModuleNotFound { program: i64, module: u32 }`, `TypeNotFound { program: i64, type_id: u32 }`, `IntegrityError { reason: String }`, `ReconstructionError { reason: String }`
   - Do NOT include `Sqlite` or `Migration` variants yet (those come in Plan 02)

3. Create `crates/lmlang-storage/src/types.rs`:
   - `ProgramId(pub i64)` newtype with `Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize`
   - `ProgramSummary` struct with `id: ProgramId`, `name: String`
   - `Display` impl for `ProgramId`

4. Create `crates/lmlang-storage/src/traits.rs`:
   - `GraphStore` trait (sync, not async) with `Result<T, StorageError>` returns
   - Per the user's locked decision: two-layer API with low-level CRUD as trait foundation
   - Program-level: `create_program(&mut self, name: &str) -> Result<ProgramId>`, `load_program(&self, id: ProgramId) -> Result<ProgramGraph>`, `delete_program(&mut self, id: ProgramId) -> Result<()>`, `list_programs(&self) -> Result<Vec<ProgramSummary>>`
   - High-level convenience: `save_program(&mut self, id: ProgramId, graph: &ProgramGraph) -> Result<()>` (bulk save/update)
   - Node CRUD: `insert_node`, `get_node`, `update_node`, `delete_node` -- all take `ProgramId` + `NodeId` + `&ComputeNode` as appropriate
   - Edge CRUD: `insert_edge` (with source/target NodeIds + &FlowEdge), `get_edge`, `delete_edge`
   - Type CRUD: `insert_type`, `get_type`
   - Function CRUD: `insert_function`, `get_function`, `update_function`
   - Module CRUD: `insert_module`, `get_module`
   - Semantic CRUD: `insert_semantic_node`, `get_semantic_node`, `insert_semantic_edge`, `get_semantic_edge`
   - Query methods (per user decision): `find_nodes_by_owner(ProgramId, FunctionId)`, `find_edges_from(ProgramId, NodeId)`, `find_edges_to(ProgramId, NodeId)`, `find_functions_in_module(ProgramId, ModuleId)`
   - Use `u32` for semantic node/edge indices (matching petgraph NodeIndex/EdgeIndex inner value)

5. Modify `crates/lmlang-core/src/graph.rs`:
   - Add public accessor methods needed for decompose/recompose:
     - `pub fn functions(&self) -> &HashMap<FunctionId, FunctionDef>` (read-only access to function map)
     - `pub fn module_semantic_indices(&self) -> &HashMap<ModuleId, NodeIndex<u32>>` (semantic node mappings)
     - `pub fn function_semantic_indices(&self) -> &HashMap<FunctionId, NodeIndex<u32>>` (semantic node mappings)
     - `pub fn next_function_id(&self) -> u32` (counter for reconstruction)
   - Add a `from_parts` constructor that takes all components (compute StableGraph, semantic StableGraph, TypeRegistry, ModuleTree, functions HashMap, module_semantic_nodes, function_semantic_nodes, next_function_id) and returns `ProgramGraph`. This enables the storage layer to reconstruct a ProgramGraph from loaded data.
   - Keep existing `new()` constructor and all existing methods unchanged.

6. Create `crates/lmlang-storage/src/lib.rs`:
   - Declare modules: `error`, `types`, `traits`, `convert`, `memory`
   - Re-export key types: `StorageError`, `ProgramId`, `ProgramSummary`, `GraphStore`
  </action>
  <verify>
    `cargo check -p lmlang-storage` compiles without errors. `cargo check -p lmlang-core` still compiles. `cargo test -p lmlang-core` passes (no regressions from added accessors).
  </verify>
  <done>
    lmlang-storage crate exists in workspace with GraphStore trait defining full CRUD + query contract, StorageError with all failure modes, ProgramId type, and ProgramGraph has from_parts constructor + public accessors for decomposition.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement decompose/recompose and InMemoryStore with roundtrip tests</name>
  <files>
    crates/lmlang-storage/src/convert.rs
    crates/lmlang-storage/src/memory.rs
  </files>
  <action>
1. Create `crates/lmlang-storage/src/convert.rs`:
   - Define intermediate row types if helpful, or work directly with the types from lmlang-core
   - `pub fn decompose(graph: &ProgramGraph) -> DecomposedProgram` that extracts:
     - Compute nodes: Vec of (NodeId, ComputeNode) from `graph.compute().node_indices()` + `node_weight()`
     - Flow edges: Vec of (EdgeId, source_NodeId, target_NodeId, FlowEdge) from `graph.compute().edge_references()`
     - Types: all types from `graph.types` (iterate the TypeRegistry)
     - Functions: all entries from `graph.functions()`
     - Modules: all modules from `graph.modules`
     - Semantic nodes: Vec of (u32 index, SemanticNode) from `graph.semantic().node_indices()`
     - Semantic edges: Vec of (u32 index, source_u32, target_u32, SemanticEdge) from `graph.semantic().edge_references()`
     - Module semantic node mappings from `graph.module_semantic_indices()`
     - Function semantic node mappings from `graph.function_semantic_indices()`
     - next_function_id from `graph.next_function_id()`
     - ModuleTree (whole thing, for reconstruction)
   - Define `DecomposedProgram` struct holding all these Vec fields
   - `pub fn recompose(decomposed: DecomposedProgram) -> Result<ProgramGraph, StorageError>` that:
     - Sorts compute nodes by NodeId
     - Builds compute StableGraph: adds nodes in index order. CRITICAL: handle index gaps. If NodeId(0), NodeId(2), NodeId(5) exist, add placeholder nodes for gaps 1, 3, 4 then remove them after all edges are added. Or more simply: add nodes sequentially and track mapping. Actually, since StableGraph assigns indices 0,1,2,... on add_node, and we need to match stored NodeIds, the approach is: sort nodes by NodeId ascending, add them in order. If there's a gap (e.g., node 0 exists, node 1 is missing, node 2 exists), add a dummy node for index 1, then remove it after all edges are added. This preserves the index mapping.
     - Adds flow edges referencing the correct NodeIndex values
     - Builds semantic StableGraph similarly (sorted by index, gap-filling if needed)
     - Adds semantic edges
     - Reconstructs TypeRegistry from stored types
     - Uses `ProgramGraph::from_parts()` to build the final graph
   - Add unit tests:
     - `test_decompose_recompose_roundtrip`: Build a multi-function ProgramGraph, decompose, recompose, verify node/edge/function/semantic counts match
     - `test_decompose_recompose_with_closure`: Include a closure, verify captures survive roundtrip
     - `test_decompose_recompose_preserves_node_ids`: Verify that NodeIds in function entry_node and edge source/target reference the correct nodes after recompose

2. Create `crates/lmlang-storage/src/memory.rs`:
   - `InMemoryStore` struct with `programs: HashMap<ProgramId, StoredProgram>`, `next_program_id: i64`
   - `StoredProgram` with `name: String`, nodes/edges/types/functions/modules/semantic data stored in HashMaps/Vecs
   - Implement `GraphStore for InMemoryStore`:
     - `create_program`: allocate ProgramId, insert empty StoredProgram
     - `save_program`: decompose ProgramGraph, store all rows
     - `load_program`: collect all stored data, recompose into ProgramGraph
     - `delete_program`: remove from HashMap
     - `list_programs`: iterate programs, return summaries
     - All CRUD methods: direct HashMap insert/get/remove operations
     - Query methods: filter in-memory (find_nodes_by_owner filters by owner field, etc.)
   - Add tests:
     - `test_create_and_load_program`: create, save a ProgramGraph, load back, verify equality
     - `test_list_programs`: create multiple, list, verify all present
     - `test_delete_program`: create, delete, verify load returns ProgramNotFound
     - `test_crud_nodes`: insert, get, update, delete individual nodes
     - `test_crud_edges`: insert, get, delete edges
     - `test_query_nodes_by_owner`: add nodes with different owners, query returns correct subset
     - `test_save_load_roundtrip_full_program`: Build the multi-function closure program from Phase 1 integration test, save via InMemoryStore, load back, verify all data matches (node count, edge count, function count, semantic count, closure captures, entry nodes)
  </action>
  <verify>
    `cargo test -p lmlang-storage` passes all tests. The roundtrip test proves a complete ProgramGraph survives save+load through InMemoryStore without data loss.
  </verify>
  <done>
    InMemoryStore is a first-class GraphStore backend. ProgramGraph decompose/recompose roundtrip preserves all nodes, edges, types, functions, modules, and semantic data. Full program with closures survives save/load cycle.
  </done>
</task>

</tasks>

<verification>
1. `cargo check --workspace` compiles without errors
2. `cargo test -p lmlang-core` passes (no regressions)
3. `cargo test -p lmlang-storage` passes all tests
4. The InMemoryStore roundtrip test proves STORE-02: GraphStore is swappable (InMemoryStore works identically to how SQLite will work)
5. ProgramGraph::from_parts enables storage backends to reconstruct programs from any storage format
</verification>

<success_criteria>
- GraphStore trait compiles and defines full CRUD + query contract
- InMemoryStore implements GraphStore completely
- A multi-function program with closures survives InMemoryStore save/load roundtrip with all data intact
- ProgramId is defined in lmlang-storage (not lmlang-core)
- StorageError covers all anticipated failure modes
</success_criteria>

<output>
After completion, create `.planning/phases/02-storage-persistence/02-01-SUMMARY.md`
</output>
